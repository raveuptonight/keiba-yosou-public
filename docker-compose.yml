services:
  # Redis キャッシュ
  redis:
    image: redis:7-alpine
    container_name: keiba-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  # スケジューラ（定期実行管理）
  scheduler:
    image: mcuadros/ofelia:latest
    container_name: keiba-scheduler
    depends_on:
      - api
    command: daemon --docker
    environment:
      - TZ=Asia/Tokyo
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    labels:
      ofelia.enabled: "true"
    restart: unless-stopped

  # FastAPI サーバー
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: keiba-api
    ports:
      - "8000:8000"
    environment:
      - PYTHONDONTWRITEBYTECODE=1
      - DB_MODE=${DB_MODE:-mock}
      - DB_HOST=host.docker.internal
      - DB_PORT=5432
      - DB_NAME=keiba_db
      - DB_USER=postgres
      - DB_PASSWORD=${DB_PASSWORD}
      - NVIDIA_VISIBLE_DEVICES=all
      - REDIS_ENABLED=${REDIS_ENABLED:-false}
      - REDIS_URL=redis://redis:6379
      - SENTRY_DSN=${SENTRY_DSN:-}
      - SENTRY_ENVIRONMENT=${SENTRY_ENVIRONMENT:-production}
    volumes:
      - ./src:/app/src:ro        # ソースコード（読み取り専用）
      - ./models:/app/models
      - ./logs:/app/logs
      - ./backtest_results:/app/backtest_results
    command: uvicorn src.api.main:app --host 0.0.0.0 --port 8000
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Discord Bot
  discord-bot:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: keiba-discord-bot
    command: python -m src.discord.bot
    environment:
      - TZ=Asia/Tokyo
      - PYTHONDONTWRITEBYTECODE=1
      - DB_MODE=${DB_MODE:-mock}
      - DB_HOST=host.docker.internal
      - DB_PORT=5432
      - DB_NAME=keiba_db
      - DB_USER=postgres
      - DB_PASSWORD=${DB_PASSWORD}
      - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN}
      - DISCORD_NOTIFICATION_CHANNEL_ID=${DISCORD_NOTIFICATION_CHANNEL_ID}
      - DISCORD_COMMAND_CHANNEL_ID=${DISCORD_COMMAND_CHANNEL_ID}
      - DISCORD_GUILD_ID=${DISCORD_GUILD_ID}
      - API_BASE_URL=http://api:8000
    volumes:
      - ./src:/app/src:ro        # ソースコード（読み取り専用）
      - ./models:/app/models
      - ./logs:/app/logs
      - /etc/localtime:/etc/localtime:ro  # ホストのタイムゾーンを使用
    depends_on:
      api:
        condition: service_healthy
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # 機械学習ジョブ（定期実行）
  ml-trainer:
    build:
      context: .
      dockerfile: Dockerfile.ml
    container_name: keiba-ml-trainer
    # コンテナを常駐させる（Ofeliaのjob-execに必要）
    command: tail -f /dev/null
    environment:
      - TZ=Asia/Tokyo
      - DB_MODE=${DB_MODE:-mock}
      - DB_HOST=host.docker.internal
      - DB_PORT=5432
      - DB_NAME=keiba_db
      - DB_USER=postgres
      - DB_PASSWORD=${DB_PASSWORD}
      - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN}
      - DISCORD_NOTIFICATION_CHANNEL_ID=${DISCORD_NOTIFICATION_CHANNEL_ID}
      - API_BASE_URL=http://api:8000
      - NVIDIA_VISIBLE_DEVICES=all
      # Git credentials for model version control
      - GIT_USER_NAME=${GIT_USER_NAME:-keiba-bot}
      - GIT_USER_EMAIL=${GIT_USER_EMAIL:-bot@example.com}
      - GITHUB_TOKEN=${GITHUB_TOKEN:-}
    depends_on:
      api:
        condition: service_healthy
    volumes:
      - ./src:/app/src:ro
      - ./models:/app/models
      - ./logs:/app/logs
      - ./backtest_results:/app/backtest_results
      - ./.git:/app/.git  # Git repository for model version control
    extra_hosts:
      - "host.docker.internal:host-gateway"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    labels:
      ofelia.enabled: "true"
      # Ofelia uses 6-field cron: second minute hour day month weekday
      # 毎日21:00 - 当日結果分析・Discord通知（開催日のみ実行）
      ofelia.job-exec.result-daily.schedule: "0 0 21 * * *"
      ofelia.job-exec.result-daily.command: "python -m src.scheduler.result_collector --today"
      # 毎週火曜18:00 - 週末サマリ（週末のレース結果を分析・DB保存）
      ofelia.job-exec.result-collect.schedule: "0 0 18 * * 2"
      ofelia.job-exec.result-collect.command: "python -m src.scheduler.result_collector --weekend"
      # 毎週火曜23:00 - モデル再学習
      ofelia.job-exec.weekly-retrain.schedule: "0 0 23 * * 2"
      ofelia.job-exec.weekly-retrain.command: "python -m src.scheduler.weekly_retrain_model"
    restart: unless-stopped

  # Streamlit ダッシュボード
  streamlit:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: keiba-streamlit
    command: streamlit run streamlit/app.py --server.port 8501 --server.address 0.0.0.0
    ports:
      - "8501:8501"
    environment:
      - TZ=Asia/Tokyo
      - PYTHONDONTWRITEBYTECODE=1
      - DB_MODE=${DB_MODE:-mock}
      - DB_HOST=host.docker.internal
      - DB_PORT=5432
      - DB_NAME=keiba_db
      - DB_USER=postgres
      - DB_PASSWORD=${DB_PASSWORD}
      - API_BASE_URL=http://api:8000
    volumes:
      - ./src:/app/src:ro
      - ./streamlit:/app/streamlit:ro
      - ./backtest_results:/app/backtest_results:ro
      - ./models:/app/models:ro
    depends_on:
      api:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

volumes:
  redis_data:

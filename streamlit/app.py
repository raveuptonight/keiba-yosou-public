"""
keiba-yosou Dashboard - Main Application

Streamlit dashboard for horse racing prediction system.
Displays hit rates, ROI, and model statistics from database.
"""

import os
import sys
from datetime import datetime
from pathlib import Path

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

import streamlit as st

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

# Page configuration
st.set_page_config(
    page_title="ç«¶é¦¬äºˆæƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    page_icon="ğŸ‡",
    layout="wide",
    initial_sidebar_state="expanded",
)


# =============================================================================
# Database Functions
# =============================================================================


def get_db_connection():
    """Get database connection."""
    try:
        import psycopg2

        conn = psycopg2.connect(
            host=os.getenv("DB_HOST", "host.docker.internal"),
            port=os.getenv("DB_PORT", "5432"),
            database=os.getenv("DB_NAME", "keiba_db"),
            user=os.getenv("DB_USER", "postgres"),
            password=os.getenv("DB_PASSWORD", ""),
        )
        return conn
    except Exception as e:
        st.error(f"DBæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return None


@st.cache_data(ttl=300)
def get_analysis_results(days: int = 30) -> pd.DataFrame:
    """Get analysis results from database."""
    conn = get_db_connection()
    if not conn:
        return pd.DataFrame()

    try:
        query = """
            SELECT
                analysis_date,
                total_races,
                analyzed_races,
                tansho_hit,
                fukusho_hit,
                umaren_hit,
                sanrenpuku_hit,
                top3_cover,
                tansho_rate,
                fukusho_rate,
                umaren_rate,
                sanrenpuku_rate,
                top3_cover_rate,
                mrr,
                tansho_roi,
                fukusho_roi,
                axis_fukusho_roi,
                tansho_investment,
                tansho_return,
                fukusho_investment,
                fukusho_return
            FROM analysis_results
            WHERE analysis_date >= CURRENT_DATE - INTERVAL '%s days'
            ORDER BY analysis_date DESC
        """
        df = pd.read_sql_query(query, conn, params=(days,))
        return df
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()
    finally:
        conn.close()


@st.cache_data(ttl=300)
def get_cumulative_stats() -> dict | None:
    """Get cumulative statistics."""
    conn = get_db_connection()
    if not conn:
        return None

    try:
        cur = conn.cursor()
        cur.execute(
            """
            SELECT
                total_races,
                total_tansho_hit,
                total_fukusho_hit,
                total_umaren_hit,
                total_sanrenpuku_hit,
                cumulative_tansho_rate,
                cumulative_fukusho_rate,
                cumulative_umaren_rate,
                cumulative_sanrenpuku_rate,
                last_updated
            FROM accuracy_tracking
            LIMIT 1
        """
        )
        row = cur.fetchone()
        cur.close()

        if row:
            return {
                "total_races": row[0] or 0,
                "tansho_hit": row[1] or 0,
                "fukusho_hit": row[2] or 0,
                "umaren_hit": row[3] or 0,
                "sanrenpuku_hit": row[4] or 0,
                "tansho_rate": row[5] or 0,
                "fukusho_rate": row[6] or 0,
                "umaren_rate": row[7] or 0,
                "sanrenpuku_rate": row[8] or 0,
                "last_updated": row[9],
            }
        return None
    except Exception as e:
        st.error(f"ç´¯ç©çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    finally:
        conn.close()


@st.cache_data(ttl=600)
def get_model_info() -> dict | None:
    """Get model information from model file or database."""
    # Try loading from pickle file first
    try:
        import joblib

        model_path = Path("/app/models/ensemble_model_latest.pkl")
        if not model_path.exists():
            model_path = Path("models/ensemble_model_latest.pkl")

        if model_path.exists():
            model_data = joblib.load(model_path)

            if isinstance(model_data, dict):
                feature_names = model_data.get("feature_names", [])
                weights = model_data.get("weights", {})

                return {
                    "trained_at": model_data.get("trained_at", "ä¸æ˜"),
                    "version": model_data.get("version", "ä¸æ˜"),
                    "feature_count": len(feature_names),
                    "rmse": model_data.get("rmse"),
                    "win_accuracy": model_data.get("win_accuracy"),
                    "place_accuracy": model_data.get("place_accuracy"),
                    "win_auc": model_data.get("win_auc"),
                    "place_auc": model_data.get("place_auc"),
                    "weights": weights,
                    "samples": model_data.get("samples"),
                }
    except Exception:
        pass  # Fall through to database lookup

    # Fallback: try to get model info from database
    conn = get_db_connection()
    if conn:
        try:
            cur = conn.cursor()
            cur.execute(
                """
                SELECT model_version, calibration_data, created_at
                FROM model_calibration
                WHERE is_active = TRUE
                ORDER BY created_at DESC
                LIMIT 1
            """
            )
            row = cur.fetchone()
            cur.close()

            if row:
                import json

                calibration_data = row[1]
                if isinstance(calibration_data, str):
                    calibration_data = json.loads(calibration_data)

                return {
                    "trained_at": row[2].strftime("%Y-%m-%d %H:%M") if row[2] else "ä¸æ˜",
                    "version": row[0] or "ä¸æ˜",
                    "feature_count": calibration_data.get("feature_count", "ä¸æ˜"),
                    "win_auc": calibration_data.get("win_auc"),
                    "place_auc": calibration_data.get("place_auc"),
                    "weights": calibration_data.get("weights", {}),
                    "samples": calibration_data.get("samples"),
                }
        except Exception:
            pass
        finally:
            conn.close()

    # Return default values if all else fails
    return {
        "trained_at": "ä¸æ˜ï¼ˆPickleäº’æ›æ€§ã‚¨ãƒ©ãƒ¼ï¼‰",
        "version": "ensemble_v3",
        "feature_count": 42,
        "weights": {"xgboost": 0.4, "lightgbm": 0.35, "catboost": 0.25},
    }


# =============================================================================
# Sidebar
# =============================================================================

with st.sidebar:
    st.title("ğŸ‡ ç«¶é¦¬äºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("---")

    # Date range selector
    st.subheader("æœŸé–“é¸æŠ")
    date_options = {
        "éå»7æ—¥": 7,
        "éå»30æ—¥": 30,
        "éå»90æ—¥": 90,
        "éå»180æ—¥": 180,
    }
    date_range = st.selectbox(
        "è¡¨ç¤ºæœŸé–“",
        list(date_options.keys()),
        index=1,
    )
    selected_days = date_options[date_range]

    st.markdown("---")

    # Quick links
    st.subheader("ã‚¯ã‚¤ãƒƒã‚¯ãƒªãƒ³ã‚¯")
    st.markdown(
        """
    - [API Docs](http://localhost:8000/docs)
    - [GitHub](https://github.com/raveuptonight/keiba-yosou)
    """
    )

    st.markdown("---")

    # Refresh button
    if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ›´æ–°"):
        st.cache_data.clear()
        st.rerun()

    st.caption(f"Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M')}")


# =============================================================================
# Main Content
# =============================================================================

st.title("ğŸ‡ ç«¶é¦¬äºˆæƒ³ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.markdown("æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ï¼ˆXGBoost + LightGBM + CatBoostï¼‰ã«ã‚ˆã‚‹ç«¶é¦¬äºˆæƒ³ã‚·ã‚¹ãƒ†ãƒ ")

# Load data
analysis_df = get_analysis_results(selected_days)
cumulative = get_cumulative_stats()
model_info = get_model_info()

# =============================================================================
# Summary Metrics (Cumulative)
# =============================================================================

st.markdown("## ğŸ“Š ç´¯ç©æˆç¸¾")

if cumulative:
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            label="ç·ãƒ¬ãƒ¼ã‚¹æ•°",
            value=f"{cumulative['total_races']:,}",
        )

    with col2:
        st.metric(
            label="å˜å‹çš„ä¸­ç‡",
            value=f"{cumulative['tansho_rate']:.1f}%",
            help="TOP1äºˆæƒ³ã®å˜å‹çš„ä¸­ç‡",
        )

    with col3:
        st.metric(
            label="è¤‡å‹çš„ä¸­ç‡",
            value=f"{cumulative['fukusho_rate']:.1f}%",
            help="TOP1äºˆæƒ³ã®è¤‡å‹çš„ä¸­ç‡",
        )

    with col4:
        st.metric(
            label="3é€£è¤‡çš„ä¸­ç‡",
            value=f"{cumulative['sanrenpuku_rate']:.1f}%",
            help="TOP3äºˆæƒ³ã®3é€£è¤‡çš„ä¸­ç‡",
        )

    if cumulative.get("last_updated"):
        st.caption(f"æœ€çµ‚æ›´æ–°: {cumulative['last_updated']}")
else:
    st.info("ç´¯ç©ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ¬ãƒ¼ã‚¹çµæœã®åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

st.markdown("---")

# =============================================================================
# Charts Section - Daily Performance
# =============================================================================

st.markdown("## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¨ç§»")

if not analysis_df.empty:
    # Sort by date for charts
    chart_df = analysis_df.sort_values("analysis_date")

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("çš„ä¸­ç‡æ¨ç§»")
        fig_rate = go.Figure()

        fig_rate.add_trace(
            go.Scatter(
                x=chart_df["analysis_date"],
                y=chart_df["tansho_rate"],
                mode="lines+markers",
                name="å˜å‹",
                line={"color": "#1f77b4"},
            )
        )
        fig_rate.add_trace(
            go.Scatter(
                x=chart_df["analysis_date"],
                y=chart_df["fukusho_rate"],
                mode="lines+markers",
                name="è¤‡å‹",
                line={"color": "#2ca02c"},
            )
        )
        fig_rate.add_trace(
            go.Scatter(
                x=chart_df["analysis_date"],
                y=chart_df["top3_cover_rate"],
                mode="lines+markers",
                name="TOP3ã‚«ãƒãƒ¼ç‡",
                line={"color": "#ff7f0e"},
            )
        )

        fig_rate.update_layout(
            xaxis_title="æ—¥ä»˜",
            yaxis_title="çš„ä¸­ç‡ (%)",
            height=400,
            legend={"x": 0.02, "y": 0.98},
        )
        st.plotly_chart(fig_rate, use_container_width=True)

    with col2:
        st.subheader("å›åç‡æ¨ç§»")
        fig_roi = go.Figure()

        # Filter rows with ROI data
        roi_df = chart_df[chart_df["tansho_roi"].notna()]

        if not roi_df.empty:
            fig_roi.add_trace(
                go.Scatter(
                    x=roi_df["analysis_date"],
                    y=roi_df["tansho_roi"],
                    mode="lines+markers",
                    name="å˜å‹ROI",
                    line={"color": "#1f77b4"},
                )
            )
            fig_roi.add_trace(
                go.Scatter(
                    x=roi_df["analysis_date"],
                    y=roi_df["fukusho_roi"],
                    mode="lines+markers",
                    name="è¤‡å‹ROI",
                    line={"color": "#2ca02c"},
                )
            )
            fig_roi.add_trace(
                go.Scatter(
                    x=roi_df["analysis_date"],
                    y=roi_df["axis_fukusho_roi"],
                    mode="lines+markers",
                    name="è»¸é¦¬è¤‡å‹ROI",
                    line={"color": "#d62728"},
                )
            )

            # 100% breakeven line
            fig_roi.add_hline(
                y=100, line_dash="dash", line_color="gray", annotation_text="æç›Šåˆ†å²ç‚¹"
            )

        fig_roi.update_layout(
            xaxis_title="æ—¥ä»˜",
            yaxis_title="å›åç‡ (%)",
            height=400,
            legend={"x": 0.02, "y": 0.98},
        )
        st.plotly_chart(fig_roi, use_container_width=True)

    # Summary table with ROI
    st.subheader("æ—¥åˆ¥ã‚µãƒãƒªãƒ¼")
    display_cols = [
        "analysis_date",
        "analyzed_races",
        "tansho_rate",
        "tansho_roi",
        "fukusho_rate",
        "fukusho_roi",
        "axis_fukusho_roi",
    ]
    display_df = analysis_df[display_cols].copy()
    display_df.columns = [
        "æ—¥ä»˜",
        "Ræ•°",
        "å˜å‹ç‡",
        "å˜å‹ROI",
        "è¤‡å‹ç‡",
        "è¤‡å‹ROI",
        "è»¸é¦¬ROI",
    ]

    # Format percentages
    for col in ["å˜å‹ç‡", "å˜å‹ROI", "è¤‡å‹ç‡", "è¤‡å‹ROI", "è»¸é¦¬ROI"]:
        display_df[col] = display_df[col].apply(lambda x: f"{x:.1f}%" if pd.notna(x) else "-")

    st.dataframe(display_df, use_container_width=True, hide_index=True)

else:
    st.info("åˆ†æãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚çµæœåˆ†æã‚¸ãƒ§ãƒ–ã®å®Ÿè¡Œå¾Œã«ãƒ‡ãƒ¼ã‚¿ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

st.markdown("---")

# =============================================================================
# Model Information
# =============================================================================

st.markdown("## ğŸ¤– ãƒ¢ãƒ‡ãƒ«æƒ…å ±")

col1, col2 = st.columns(2)

with col1:
    st.subheader("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ§‹æˆ")

    if model_info and model_info.get("weights"):
        weights = model_info["weights"]
        model_weights = pd.DataFrame(
            {
                "ãƒ¢ãƒ‡ãƒ«": list(weights.keys()),
                "é‡ã¿": list(weights.values()),
            }
        )
        fig_weights = px.pie(
            model_weights,
            values="é‡ã¿",
            names="ãƒ¢ãƒ‡ãƒ«",
            title="ãƒ¢ãƒ‡ãƒ«é‡ã¿é…åˆ†",
        )
        fig_weights.update_layout(height=300)
        st.plotly_chart(fig_weights, use_container_width=True)
    else:
        # Default weights display
        model_weights = pd.DataFrame(
            {
                "ãƒ¢ãƒ‡ãƒ«": ["XGBoost", "LightGBM", "CatBoost"],
                "é‡ã¿": [0.4, 0.35, 0.25],
            }
        )
        fig_weights = px.pie(
            model_weights,
            values="é‡ã¿",
            names="ãƒ¢ãƒ‡ãƒ«",
            title="ãƒ¢ãƒ‡ãƒ«é‡ã¿é…åˆ†ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰",
        )
        fig_weights.update_layout(height=300)
        st.plotly_chart(fig_weights, use_container_width=True)

with col2:
    st.subheader("ãƒ¢ãƒ‡ãƒ«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")

    if model_info:
        status_data = []
        status_data.append(("æœ€çµ‚å­¦ç¿’æ—¥", model_info.get("trained_at", "ä¸æ˜")))
        status_data.append(("ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³", model_info.get("version", "ä¸æ˜")))
        status_data.append(("ç‰¹å¾´é‡æ•°", str(model_info.get("feature_count", "ä¸æ˜"))))

        if model_info.get("samples"):
            status_data.append(("å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°", f"{model_info['samples']:,}"))

        if model_info.get("win_auc"):
            status_data.append(("Win AUC", f"{model_info['win_auc']:.4f}"))
        elif model_info.get("win_accuracy"):
            status_data.append(("Winç²¾åº¦", f"{model_info['win_accuracy']:.4f}"))

        if model_info.get("place_auc"):
            status_data.append(("Place AUC", f"{model_info['place_auc']:.4f}"))
        elif model_info.get("place_accuracy"):
            status_data.append(("Placeç²¾åº¦", f"{model_info['place_accuracy']:.4f}"))

        if model_info.get("rmse"):
            status_data.append(("RMSE", f"{model_info['rmse']:.4f}"))

        # Create markdown table
        table_md = "| é …ç›® | å€¤ |\n|------|-----|\n"
        for label, value in status_data:
            table_md += f"| {label} | {value} |\n"

        st.markdown(table_md)
    else:
        st.markdown(
            """
        | é …ç›® | å€¤ |
        |------|-----|
        | æœ€çµ‚å­¦ç¿’æ—¥ | ä¸æ˜ |
        | ç‰¹å¾´é‡æ•° | ä¸æ˜ |
        | ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ | Isotonic |

        *ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ*
        """
        )

st.markdown("---")

# =============================================================================
# Recent Period Summary
# =============================================================================

if not analysis_df.empty:
    st.markdown(f"## ğŸ“‹ {date_range}ã®é›†è¨ˆ")

    total_races = analysis_df["analyzed_races"].sum()
    total_tansho = analysis_df["tansho_hit"].sum()
    total_fukusho = analysis_df["fukusho_hit"].sum()

    # ROI calculation from investment/return totals
    total_tansho_inv = analysis_df["tansho_investment"].sum()
    total_tansho_ret = analysis_df["tansho_return"].sum()
    total_fukusho_inv = analysis_df["fukusho_investment"].sum()
    total_fukusho_ret = analysis_df["fukusho_return"].sum()

    tansho_roi = (total_tansho_ret / total_tansho_inv * 100) if total_tansho_inv > 0 else 0
    fukusho_roi = (total_fukusho_ret / total_fukusho_inv * 100) if total_fukusho_inv > 0 else 0

    col1, col2, col3, col4, col5 = st.columns(5)

    with col1:
        st.metric("åˆ†æãƒ¬ãƒ¼ã‚¹æ•°", f"{total_races:,}")

    with col2:
        rate = (total_tansho / total_races * 100) if total_races > 0 else 0
        st.metric("å˜å‹çš„ä¸­ç‡", f"{rate:.1f}%", help=f"{total_tansho}/{total_races}")

    with col3:
        delta = f"{tansho_roi - 100:+.1f}%" if tansho_roi > 0 else None
        st.metric(
            "å˜å‹å›åç‡",
            f"{tansho_roi:.1f}%",
            delta=delta,
            delta_color="normal" if tansho_roi >= 100 else "inverse",
            help=f"æŠ•è³‡{total_tansho_inv:,}å†† â†’ å›å{total_tansho_ret:,}å††",
        )

    with col4:
        rate = (total_fukusho / total_races * 100) if total_races > 0 else 0
        st.metric("è¤‡å‹çš„ä¸­ç‡", f"{rate:.1f}%", help=f"{total_fukusho}/{total_races}")

    with col5:
        delta = f"{fukusho_roi - 100:+.1f}%" if fukusho_roi > 0 else None
        st.metric(
            "è¤‡å‹å›åç‡",
            f"{fukusho_roi:.1f}%",
            delta=delta,
            delta_color="normal" if fukusho_roi >= 100 else "inverse",
            help=f"æŠ•è³‡{total_fukusho_inv:,}å†† â†’ å›å{total_fukusho_ret:,}å††",
        )

st.markdown("---")

# =============================================================================
# Footer
# =============================================================================

st.markdown(
    """
<div style="text-align: center; color: #666; font-size: 0.8em;">
    keiba-yosou v1.0.0 |
    <a href="https://github.com/raveuptonight/keiba-yosou">GitHub</a> |
    Powered by XGBoost + LightGBM + CatBoost
</div>
""",
    unsafe_allow_html=True,
)

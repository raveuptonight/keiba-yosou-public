"""
é€±æ¬¡ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

æ¯é€±ç«æ›œ23:00ã«å®Ÿè¡Œã—ã¦ï¼š
1. æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§ensemble_modelï¼ˆXGBoost + LightGBMï¼‰ã‚’å†å­¦ç¿’
2. æ–°æ—§ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ¯”è¼ƒ
3. æ”¹å–„ãŒã‚ã‚Œã°æ–°ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤
"""

import logging
import json
import os
import shutil
from datetime import datetime, date
from pathlib import Path
from typing import Dict, Optional
import joblib
import numpy as np
import pandas as pd

from src.db.connection import get_db
from src.models.fast_train import FastFeatureExtractor

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class WeeklyRetrain:
    """é€±æ¬¡å†å­¦ç¿’ã‚¯ãƒ©ã‚¹ï¼ˆensemble_modelç”¨ï¼‰"""

    def __init__(
        self,
        model_dir: str = "/app/models",
        backup_dir: str = "/app/models/backup"
    ):
        self.model_dir = Path(model_dir)
        self.backup_dir = Path(backup_dir)
        self.current_model_path = self.model_dir / "ensemble_model_latest.pkl"

    def backup_current_model(self) -> Optional[str]:
        """ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        if not self.current_model_path.exists():
            logger.warning("ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None

        self.backup_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = self.backup_dir / f"ensemble_model_{timestamp}.pkl"

        shutil.copy(self.current_model_path, backup_path)
        logger.info(f"ãƒ¢ãƒ‡ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path}")

        return str(backup_path)

    def train_new_model(self, years: int = 3) -> Dict:
        """æ–°ã—ã„ensemble_modelã‚’å­¦ç¿’"""
        import xgboost as xgb
        import lightgbm as lgb

        logger.info(f"ensemble_modelå­¦ç¿’é–‹å§‹ï¼ˆéå»{years}å¹´ï¼‰")

        db = get_db()
        conn = db.get_connection()

        try:
            extractor = FastFeatureExtractor(conn)

            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            current_year = date.today().year
            all_data = []

            for year in range(current_year - years, current_year + 1):
                logger.info(f"  {year}å¹´ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸­...")
                year_data = extractor.extract_year_data(year)
                if year_data is not None and len(year_data) > 0:
                    if isinstance(year_data, pd.DataFrame):
                        all_data.append(year_data)
                    else:
                        all_data.append(pd.DataFrame(year_data))
                    logger.info(f"    {len(year_data)}ä»¶")

            if not all_data:
                logger.error("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãªã—")
                return {'status': 'error', 'message': 'no_training_data'}

            # DataFrameçµåˆ
            df = pd.concat(all_data, ignore_index=True)
            logger.info(f"ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(df)}")

            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
            exclude_cols = ['race_code', 'umaban', 'bamei', 'target', 'kakutei_chakujun']
            feature_cols = [c for c in df.columns if c not in exclude_cols]

            X = df[feature_cols].fillna(0)
            y = df['target']

            # æ™‚ç³»åˆ—åˆ†å‰²
            split_idx = int(len(df) * 0.8)
            X_train, X_val = X[:split_idx], X[split_idx:]
            y_train, y_val = y[:split_idx], y[split_idx:]

            # XGBoostãƒ¢ãƒ‡ãƒ«
            logger.info("XGBoostãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...")
            xgb_model = xgb.XGBRegressor(
                n_estimators=200,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                n_jobs=-1
            )
            xgb_model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
                verbose=False
            )

            # LightGBMãƒ¢ãƒ‡ãƒ«
            logger.info("LightGBMãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...")
            lgb_model = lgb.LGBMRegressor(
                n_estimators=200,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                n_jobs=-1,
                verbose=-1
            )
            lgb_model.fit(
                X_train, y_train,
                eval_set=[(X_val, y_val)],
            )

            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡
            xgb_pred = xgb_model.predict(X_val)
            lgb_pred = lgb_model.predict(X_val)
            ensemble_pred = (xgb_pred + lgb_pred) / 2

            rmse = np.sqrt(np.mean((ensemble_pred - y_val) ** 2))
            logger.info(f"æ¤œè¨¼RMSE (ensemble): {rmse:.4f}")

            # ä¸€æ™‚ä¿å­˜
            temp_model_path = self.model_dir / "ensemble_model_new.pkl"
            model_data = {
                'xgb_model': xgb_model,
                'lgb_model': lgb_model,
                'feature_names': feature_cols,
                'trained_at': datetime.now().isoformat(),
                'training_samples': len(df),
                'validation_rmse': float(rmse),
                'years': years
            }
            joblib.dump(model_data, temp_model_path)

            return {
                'status': 'success',
                'model_path': str(temp_model_path),
                'rmse': float(rmse),
                'samples': len(df)
            }

        except Exception as e:
            logger.error(f"å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {'status': 'error', 'message': str(e)}

        finally:
            conn.close()

    def compare_models(self, new_model_path: str, test_year: int = None) -> Dict:
        """æ–°æ—§ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒ"""
        if test_year is None:
            test_year = date.today().year

        logger.info(f"ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼ˆãƒ†ã‚¹ãƒˆå¹´: {test_year}ï¼‰")

        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        try:
            old_model_data = joblib.load(self.current_model_path)
            new_model_data = joblib.load(new_model_path)
        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {'status': 'error', 'message': str(e)}

        old_xgb = old_model_data['xgb_model']
        old_lgb = old_model_data['lgb_model']
        old_features = old_model_data['feature_names']

        new_xgb = new_model_data['xgb_model']
        new_lgb = new_model_data['lgb_model']
        new_features = new_model_data['feature_names']

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
        db = get_db()
        conn = db.get_connection()

        try:
            extractor = FastFeatureExtractor(conn)
            test_data = extractor.extract_year_data(test_year)

            if test_data is None or len(test_data) == 0:
                return {'status': 'error', 'message': 'no_test_data'}

            if isinstance(test_data, list):
                df = pd.DataFrame(test_data)
            else:
                df = test_data

            logger.info(f"ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°: {len(df)}")

            # æ—§ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
            X_old = df[old_features].fillna(0)
            old_pred = (old_xgb.predict(X_old) + old_lgb.predict(X_old)) / 2
            old_rmse = np.sqrt(np.mean((old_pred - df['target']) ** 2))

            # æ–°ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
            X_new = df[new_features].fillna(0)
            new_pred = (new_xgb.predict(X_new) + new_lgb.predict(X_new)) / 2
            new_rmse = np.sqrt(np.mean((new_pred - df['target']) ** 2))

            improvement = (old_rmse - new_rmse) / old_rmse * 100

            logger.info(f"æ—§ãƒ¢ãƒ‡ãƒ« RMSE: {old_rmse:.4f}")
            logger.info(f"æ–°ãƒ¢ãƒ‡ãƒ« RMSE: {new_rmse:.4f}")
            logger.info(f"æ”¹å–„ç‡: {improvement:.2f}%")

            return {
                'status': 'success',
                'old_rmse': float(old_rmse),
                'new_rmse': float(new_rmse),
                'improvement': float(improvement),
                'test_samples': len(df)
            }

        finally:
            conn.close()

    def deploy_new_model(self, new_model_path: str):
        """æ–°ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤"""
        # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        self.backup_current_model()

        # æ–°ãƒ¢ãƒ‡ãƒ«ã‚’æœ¬ç•ªã«é…ç½®
        shutil.move(new_model_path, self.current_model_path)
        logger.info(f"æ–°ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†: {self.current_model_path}")

    def send_notification(self, result: Dict):
        """å†å­¦ç¿’çµæœã‚’é€šçŸ¥"""
        webhook_url = os.getenv('DISCORD_WEBHOOK_URL')
        if not webhook_url:
            return

        try:
            import requests

            if result.get('deployed'):
                lines = [
                    "ğŸ”„ **é€±æ¬¡ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’å®Œäº†**",
                    "",
                    f"ãƒ¢ãƒ‡ãƒ«: ensemble_model (XGBoost + LightGBM)",
                    f"å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°: {result['training'].get('samples', 0):,}",
                    f"æ–°ãƒ¢ãƒ‡ãƒ«RMSE: {result['comparison'].get('new_rmse', 0):.4f}",
                    f"æ”¹å–„ç‡: {result['comparison'].get('improvement', 0):.2f}%",
                    "",
                    "âœ… æ–°ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã—ãŸ"
                ]
            else:
                lines = [
                    "ğŸ”„ **é€±æ¬¡ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’å®Œäº†**",
                    "",
                    f"ãƒ¢ãƒ‡ãƒ«: ensemble_model (XGBoost + LightGBM)",
                    f"å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°: {result['training'].get('samples', 0):,}",
                    f"æ–°ãƒ¢ãƒ‡ãƒ«RMSE: {result['comparison'].get('new_rmse', 0):.4f}",
                    f"æ”¹å–„ç‡: {result['comparison'].get('improvement', 0):.2f}%",
                    "",
                    "âš ï¸ æ”¹å–„ãªã—ã®ãŸã‚ç¾è¡Œãƒ¢ãƒ‡ãƒ«ã‚’ç¶­æŒ"
                ]

            payload = {"content": "\n".join(lines)}
            requests.post(webhook_url, json=payload, timeout=10)

        except Exception as e:
            logger.error(f"é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")

    def run_weekly_job(self, force_deploy: bool = False, notify: bool = True):
        """é€±æ¬¡ã‚¸ãƒ§ãƒ–ã‚’å®Ÿè¡Œ"""
        logger.info("=" * 50)
        logger.info(f"é€±æ¬¡ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’é–‹å§‹: {datetime.now()}")
        logger.info("=" * 50)

        result = {
            'date': date.today().isoformat(),
            'deployed': False
        }

        # 1. æ–°ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        training_result = self.train_new_model(years=3)
        result['training'] = training_result

        if training_result['status'] != 'success':
            logger.error(f"å­¦ç¿’å¤±æ•—: {training_result}")
            return result

        new_model_path = training_result['model_path']

        # 2. æ¯”è¼ƒï¼ˆç¾è¡Œãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆï¼‰
        if self.current_model_path.exists():
            comparison = self.compare_models(new_model_path)
            result['comparison'] = comparison

            if comparison['status'] == 'success':
                # æ”¹å–„ãŒã‚ã‚Œã°ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆã¾ãŸã¯å¼·åˆ¶ãƒ‡ãƒ—ãƒ­ã‚¤ï¼‰
                if comparison['improvement'] > 0 or force_deploy:
                    self.deploy_new_model(new_model_path)
                    result['deployed'] = True
                    logger.info("æ–°ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã—ãŸ")
                else:
                    logger.info("æ”¹å–„ãªã—ã€ç¾è¡Œãƒ¢ãƒ‡ãƒ«ã‚’ç¶­æŒ")
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    Path(new_model_path).unlink()
        else:
            # ç¾è¡Œãƒ¢ãƒ‡ãƒ«ãŒãªã„å ´åˆã¯ãã®ã¾ã¾ãƒ‡ãƒ—ãƒ­ã‚¤
            shutil.move(new_model_path, self.current_model_path)
            result['deployed'] = True
            result['comparison'] = {'note': 'initial_deployment'}
            logger.info("åˆå›ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†")

        # 3. é€šçŸ¥
        if notify:
            self.send_notification(result)

        # çµæœä¿å­˜
        result_path = self.model_dir / f"retrain_result_{date.today().strftime('%Y%m%d')}.json"
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        return result


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    import argparse

    parser = argparse.ArgumentParser(description="é€±æ¬¡ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’ï¼ˆensemble_modelï¼‰")
    parser.add_argument("--force", "-f", action="store_true", help="æ”¹å–„ãªã—ã§ã‚‚ãƒ‡ãƒ—ãƒ­ã‚¤")
    parser.add_argument("--no-notify", action="store_true", help="Discordé€šçŸ¥ã—ãªã„")

    args = parser.parse_args()

    retrain = WeeklyRetrain()
    result = retrain.run_weekly_job(
        force_deploy=args.force,
        notify=not args.no_notify
    )

    print("\n=== å†å­¦ç¿’çµæœ ===")
    print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()

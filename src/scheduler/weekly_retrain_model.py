"""
é€±æ¬¡ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

æ¯é€±ç«æ›œ23:00ã«å®Ÿè¡Œã—ã¦ï¼š
1. æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§ensemble_modelï¼ˆXGBoost + LightGBMï¼‰ã‚’å†å­¦ç¿’
2. åˆ†é¡ãƒ¢ãƒ‡ãƒ«ï¼ˆå‹åˆ©/è¤‡å‹ï¼‰+ ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
3. æ–°æ—§ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ¯”è¼ƒ
4. æ”¹å–„ãŒã‚ã‚Œã°æ–°ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤
"""

import logging
import json
import os
import shutil
from datetime import datetime, date
from pathlib import Path
from typing import Dict, Optional
import joblib
import numpy as np
import pandas as pd
from sklearn.isotonic import IsotonicRegression

from src.db.connection import get_db
from src.models.fast_train import FastFeatureExtractor

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class WeeklyRetrain:
    """é€±æ¬¡å†å­¦ç¿’ã‚¯ãƒ©ã‚¹ï¼ˆensemble_modelç”¨ï¼‰"""

    def __init__(
        self,
        model_dir: str = None,
        backup_dir: str = None
    ):
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹: ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã¨Dockerç’°å¢ƒã®ä¸¡æ–¹ã«å¯¾å¿œ
        if model_dir is None:
            if Path("/app/models").exists():
                model_dir = "/app/models"
            else:
                model_dir = str(Path(__file__).parent.parent.parent / "models")
        if backup_dir is None:
            backup_dir = str(Path(model_dir) / "backup")
        self.model_dir = Path(model_dir)
        self.backup_dir = Path(backup_dir)
        self.current_model_path = self.model_dir / "ensemble_model_latest.pkl"

    def backup_current_model(self) -> Optional[str]:
        """ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        if not self.current_model_path.exists():
            logger.warning("ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None

        self.backup_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = self.backup_dir / f"ensemble_model_{timestamp}.pkl"

        shutil.copy(self.current_model_path, backup_path)
        logger.info(f"ãƒ¢ãƒ‡ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_path}")

        return str(backup_path)

    def train_new_model(self, years: int = 3) -> Dict:
        """æ–°ã—ã„ensemble_modelã‚’å­¦ç¿’ï¼ˆå›å¸° + åˆ†é¡ + ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"""
        import xgboost as xgb
        import lightgbm as lgb

        logger.info(f"ensemble_modelå­¦ç¿’é–‹å§‹ï¼ˆéå»{years}å¹´ï¼‰")

        db = get_db()
        conn = db.get_connection()

        try:
            extractor = FastFeatureExtractor(conn)

            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            current_year = date.today().year
            all_data = []

            for year in range(current_year - years, current_year + 1):
                logger.info(f"  {year}å¹´ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸­...")
                year_data = extractor.extract_year_data(year)
                if year_data is not None and len(year_data) > 0:
                    if isinstance(year_data, pd.DataFrame):
                        all_data.append(year_data)
                    else:
                        all_data.append(pd.DataFrame(year_data))
                    logger.info(f"    {len(year_data)}ä»¶")

            if not all_data:
                logger.error("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãªã—")
                return {'status': 'error', 'message': 'no_training_data'}

            # DataFrameçµåˆ
            df = pd.concat(all_data, ignore_index=True)
            logger.info(f"ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(df)}")

            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆæ–‡å­—åˆ—å‹ã‚«ãƒ©ãƒ ã‚’é™¤å¤–ï¼‰
            exclude_cols = ['race_code', 'umaban', 'bamei', 'target', 'kakutei_chakujun', 'kettonum']
            # æ•°å€¤å‹ã®ã¿æŠ½å‡º
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            feature_cols = [c for c in numeric_cols if c not in exclude_cols]

            X = df[feature_cols].fillna(0)
            y = df['target']

            # åˆ†é¡ç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
            y_win = (y == 1).astype(int)
            y_place = (y <= 3).astype(int)

            # æ™‚ç³»åˆ—åˆ†å‰²
            split_idx = int(len(df) * 0.8)
            X_train, X_val = X[:split_idx], X[split_idx:]
            y_train, y_val = y[:split_idx], y[split_idx:]
            y_win_train, y_win_val = y_win[:split_idx], y_win[split_idx:]
            y_place_train, y_place_val = y_place[:split_idx], y_place[split_idx:]

            logger.info(f"è¨“ç·´: {len(X_train)}, æ¤œè¨¼: {len(X_val)}")

            # å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            base_params = {
                'n_estimators': 500,
                'max_depth': 7,
                'learning_rate': 0.05,
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'random_state': 42,
                'n_jobs': -1
            }

            models = {}

            # ===== 1. å›å¸°ãƒ¢ãƒ‡ãƒ« =====
            # XGBoostå›å¸°
            logger.info("XGBoostå›å¸°ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...")
            xgb_reg = xgb.XGBRegressor(**base_params)
            xgb_reg.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)
            models['xgb_regressor'] = xgb_reg

            # LightGBMå›å¸°
            logger.info("LightGBMå›å¸°ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...")
            lgb_reg = lgb.LGBMRegressor(**base_params, verbose=-1)
            lgb_reg.fit(X_train, y_train, eval_set=[(X_val, y_val)])
            models['lgb_regressor'] = lgb_reg

            # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡
            xgb_pred = xgb_reg.predict(X_val)
            lgb_pred = lgb_reg.predict(X_val)
            ensemble_pred = (xgb_pred + lgb_pred) / 2
            rmse = np.sqrt(np.mean((ensemble_pred - y_val) ** 2))
            logger.info(f"å›å¸°RMSE (ensemble): {rmse:.4f}")

            # ===== 2. å‹åˆ©åˆ†é¡ãƒ¢ãƒ‡ãƒ« =====
            win_weight = len(y_win_train[y_win_train == 0]) / max(len(y_win_train[y_win_train == 1]), 1)

            logger.info("XGBoostå‹åˆ©åˆ†é¡ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...")
            xgb_win = xgb.XGBClassifier(**base_params, scale_pos_weight=win_weight)
            xgb_win.fit(X_train, y_win_train, eval_set=[(X_val, y_win_val)], verbose=False)
            models['xgb_win'] = xgb_win

            logger.info("LightGBMå‹åˆ©åˆ†é¡ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...")
            lgb_win = lgb.LGBMClassifier(**base_params, scale_pos_weight=win_weight, verbose=-1)
            lgb_win.fit(X_train, y_win_train, eval_set=[(X_val, y_win_val)])
            models['lgb_win'] = lgb_win

            # å‹åˆ©ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç¢ºç‡
            xgb_win_prob = xgb_win.predict_proba(X_val)[:, 1]
            lgb_win_prob = lgb_win.predict_proba(X_val)[:, 1]
            ensemble_win_prob = (xgb_win_prob + lgb_win_prob) / 2
            win_accuracy = ((ensemble_win_prob > 0.5) == y_win_val).mean()
            logger.info(f"å‹åˆ©åˆ†é¡ç²¾åº¦ (ensemble): {win_accuracy:.4f}")

            # ===== 3. è¤‡å‹åˆ†é¡ãƒ¢ãƒ‡ãƒ« =====
            place_weight = len(y_place_train[y_place_train == 0]) / max(len(y_place_train[y_place_train == 1]), 1)

            logger.info("XGBoostè¤‡å‹åˆ†é¡ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...")
            xgb_place = xgb.XGBClassifier(**base_params, scale_pos_weight=place_weight)
            xgb_place.fit(X_train, y_place_train, eval_set=[(X_val, y_place_val)], verbose=False)
            models['xgb_place'] = xgb_place

            logger.info("LightGBMè¤‡å‹åˆ†é¡ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­...")
            lgb_place = lgb.LGBMClassifier(**base_params, scale_pos_weight=place_weight, verbose=-1)
            lgb_place.fit(X_train, y_place_train, eval_set=[(X_val, y_place_val)])
            models['lgb_place'] = lgb_place

            # è¤‡å‹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç¢ºç‡
            xgb_place_prob = xgb_place.predict_proba(X_val)[:, 1]
            lgb_place_prob = lgb_place.predict_proba(X_val)[:, 1]
            ensemble_place_prob = (xgb_place_prob + lgb_place_prob) / 2
            place_accuracy = ((ensemble_place_prob > 0.5) == y_place_val).mean()
            logger.info(f"è¤‡å‹åˆ†é¡ç²¾åº¦ (ensemble): {place_accuracy:.4f}")

            # ===== è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®— =====
            from sklearn.metrics import roc_auc_score, brier_score_loss

            # AUC-ROC
            win_auc = roc_auc_score(y_win_val, ensemble_win_prob)
            place_auc = roc_auc_score(y_place_val, ensemble_place_prob)

            # Brier Scoreï¼ˆå‹åˆ©äºˆæ¸¬ï¼‰
            win_brier = brier_score_loss(y_win_val, ensemble_win_prob)

            # Top-3ã‚«ãƒãƒ¼ç‡ï¼ˆãƒ¬ãƒ¼ã‚¹ã”ã¨ã«å‹ã¡é¦¬ãŒäºˆæ¸¬TOP3ã«å…¥ã£ã¦ã„ã‚‹ã‹ï¼‰
            val_df = df.iloc[split_idx:].copy()
            val_df['pred_score'] = ensemble_pred
            val_df['win_prob'] = ensemble_win_prob

            top3_hits = 0
            total_races = 0
            for race_code, group in val_df.groupby('race_code'):
                if len(group) < 3:
                    continue
                # å‹ã¡é¦¬ã‚’ç‰¹å®š
                winner = group[group['target'] == 1]
                if len(winner) == 0:
                    continue
                # äºˆæ¸¬ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆï¼ˆä½ã„ã»ã©ä¸Šä½ï¼‰
                sorted_group = group.sort_values('pred_score')
                top3_horses = sorted_group.head(3).index.tolist()
                # å‹ã¡é¦¬ãŒTOP3ã«å«ã¾ã‚Œã‚‹ã‹
                if winner.index[0] in top3_horses:
                    top3_hits += 1
                total_races += 1

            top3_coverage = top3_hits / total_races if total_races > 0 else 0

            # è©•ä¾¡çµæœã‚’ãƒ­ã‚°å‡ºåŠ›
            logger.info("=" * 50)
            logger.info("ğŸ“Š ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™")
            logger.info("=" * 50)
            logger.info(f"å‹åˆ©AUC:      {win_auc:.4f}  {'âœ… è‰¯å¥½' if win_auc >= 0.70 else 'âš ï¸ è¦æ”¹å–„'} {'ğŸŒŸ å„ªç§€' if win_auc >= 0.80 else ''}")
            logger.info(f"è¤‡å‹AUC:      {place_auc:.4f}  {'âœ… è‰¯å¥½' if place_auc >= 0.65 else 'âš ï¸ è¦æ”¹å–„'} {'ğŸŒŸ å„ªç§€' if place_auc >= 0.75 else ''}")
            logger.info(f"Brier(å‹åˆ©):  {win_brier:.4f}  {'âœ… è‰¯å¥½' if win_brier <= 0.07 else 'âš ï¸ è¦æ”¹å–„'} {'ğŸŒŸ å„ªç§€' if win_brier <= 0.05 else ''}")
            logger.info(f"Top-3ã‚«ãƒãƒ¼ç‡: {top3_coverage*100:.1f}%  {'âœ… è‰¯å¥½' if top3_coverage >= 0.55 else 'âš ï¸ è¦æ”¹å–„'} {'ğŸŒŸ å„ªç§€' if top3_coverage >= 0.65 else ''}")
            logger.info("=" * 50)

            # ===== 4. ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ =====
            logger.info("ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å­¦ç¿’ä¸­...")
            win_calibrator = IsotonicRegression(out_of_bounds='clip')
            win_calibrator.fit(ensemble_win_prob, y_win_val)
            models['win_calibrator'] = win_calibrator

            place_calibrator = IsotonicRegression(out_of_bounds='clip')
            place_calibrator.fit(ensemble_place_prob, y_place_val)
            models['place_calibrator'] = place_calibrator

            calibrated_win = win_calibrator.predict(ensemble_win_prob)
            calibrated_place = place_calibrator.predict(ensemble_place_prob)
            logger.info(f"ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¾Œ - å‹ç‡å¹³å‡: {calibrated_win.mean():.4f}, è¤‡å‹ç‡å¹³å‡: {calibrated_place.mean():.4f}")

            # ä¸€æ™‚ä¿å­˜
            temp_model_path = self.model_dir / "ensemble_model_new.pkl"
            model_data = {
                # å¾Œæ–¹äº’æ›æ€§
                'xgb_model': xgb_reg,
                'lgb_model': lgb_reg,
                # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ç¾¤
                'models': models,
                'feature_names': feature_cols,
                'trained_at': datetime.now().isoformat(),
                'training_samples': len(df),
                'validation_rmse': float(rmse),
                'win_accuracy': float(win_accuracy),
                'place_accuracy': float(place_accuracy),
                # è©•ä¾¡æŒ‡æ¨™
                'win_auc': float(win_auc),
                'place_auc': float(place_auc),
                'win_brier': float(win_brier),
                'top3_coverage': float(top3_coverage),
                'years': years,
                'version': 'v2_enhanced_ensemble'
            }
            joblib.dump(model_data, temp_model_path)

            return {
                'status': 'success',
                'model_path': str(temp_model_path),
                'rmse': float(rmse),
                'win_accuracy': float(win_accuracy),
                'place_accuracy': float(place_accuracy),
                'win_auc': float(win_auc),
                'place_auc': float(place_auc),
                'win_brier': float(win_brier),
                'top3_coverage': float(top3_coverage),
                'samples': len(df)
            }

        except Exception as e:
            logger.error(f"å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            return {'status': 'error', 'message': str(e)}

        finally:
            conn.close()

    def compare_models(self, new_model_path: str, test_year: int = None) -> Dict:
        """æ–°æ—§ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒ"""
        if test_year is None:
            test_year = date.today().year

        logger.info(f"ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒï¼ˆãƒ†ã‚¹ãƒˆå¹´: {test_year}ï¼‰")

        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        try:
            old_model_data = joblib.load(self.current_model_path)
            new_model_data = joblib.load(new_model_path)
        except Exception as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {'status': 'error', 'message': str(e)}

        old_xgb = old_model_data['xgb_model']
        old_lgb = old_model_data['lgb_model']
        old_features = old_model_data['feature_names']

        new_xgb = new_model_data['xgb_model']
        new_lgb = new_model_data['lgb_model']
        new_features = new_model_data['feature_names']

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
        db = get_db()
        conn = db.get_connection()

        try:
            extractor = FastFeatureExtractor(conn)
            test_data = extractor.extract_year_data(test_year)

            if test_data is None or len(test_data) == 0:
                return {'status': 'error', 'message': 'no_test_data'}

            if isinstance(test_data, list):
                df = pd.DataFrame(test_data)
            else:
                df = test_data

            logger.info(f"ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°: {len(df)}")

            # æ—§ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
            X_old = df[old_features].fillna(0)
            old_pred = (old_xgb.predict(X_old) + old_lgb.predict(X_old)) / 2
            old_rmse = np.sqrt(np.mean((old_pred - df['target']) ** 2))

            # æ–°ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰
            X_new = df[new_features].fillna(0)
            new_pred = (new_xgb.predict(X_new) + new_lgb.predict(X_new)) / 2
            new_rmse = np.sqrt(np.mean((new_pred - df['target']) ** 2))

            improvement = (old_rmse - new_rmse) / old_rmse * 100

            logger.info(f"æ—§ãƒ¢ãƒ‡ãƒ« RMSE: {old_rmse:.4f}")
            logger.info(f"æ–°ãƒ¢ãƒ‡ãƒ« RMSE: {new_rmse:.4f}")
            logger.info(f"æ”¹å–„ç‡: {improvement:.2f}%")

            return {
                'status': 'success',
                'old_rmse': float(old_rmse),
                'new_rmse': float(new_rmse),
                'improvement': float(improvement),
                'test_samples': len(df)
            }

        finally:
            conn.close()

    def deploy_new_model(self, new_model_path: str):
        """æ–°ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤"""
        # ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        self.backup_current_model()

        # æ–°ãƒ¢ãƒ‡ãƒ«ã‚’æœ¬ç•ªã«é…ç½®
        shutil.move(new_model_path, self.current_model_path)
        logger.info(f"æ–°ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†: {self.current_model_path}")

    def send_notification(self, result: Dict):
        """å†å­¦ç¿’çµæœã‚’é€šçŸ¥"""
        webhook_url = os.getenv('DISCORD_WEBHOOK_URL')
        if not webhook_url:
            return

        try:
            import requests

            training = result.get('training', {})

            # è©•ä¾¡æŒ‡æ¨™ã‚’å–å¾—
            win_auc = training.get('win_auc', 0)
            place_auc = training.get('place_auc', 0)
            win_brier = training.get('win_brier', 0)
            top3_coverage = training.get('top3_coverage', 0)

            # è©•ä¾¡ã‚¢ã‚¤ã‚³ãƒ³
            def get_icon(value, good, excellent, lower_is_better=False):
                if lower_is_better:
                    if value <= excellent:
                        return "ğŸŒŸ"
                    elif value <= good:
                        return "âœ…"
                    else:
                        return "âš ï¸"
                else:
                    if value >= excellent:
                        return "ğŸŒŸ"
                    elif value >= good:
                        return "âœ…"
                    else:
                        return "âš ï¸"

            if result.get('deployed'):
                lines = [
                    "ğŸ”„ **é€±æ¬¡ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’å®Œäº†**",
                    "",
                    f"å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°: {training.get('samples', 0):,}",
                    "",
                    "ğŸ“Š **è©•ä¾¡æŒ‡æ¨™:**",
                    f"```",
                    f"å‹åˆ©AUC:       {win_auc:.4f} {get_icon(win_auc, 0.70, 0.80)}",
                    f"è¤‡å‹AUC:       {place_auc:.4f} {get_icon(place_auc, 0.65, 0.75)}",
                    f"Brier(å‹åˆ©):   {win_brier:.4f} {get_icon(win_brier, 0.07, 0.05, True)}",
                    f"Top-3ã‚«ãƒãƒ¼ç‡: {top3_coverage*100:.1f}% {get_icon(top3_coverage, 0.55, 0.65)}",
                    f"```",
                    "",
                    "âœ… æ–°ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã—ãŸ"
                ]
            else:
                lines = [
                    "ğŸ”„ **é€±æ¬¡ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’å®Œäº†**",
                    "",
                    f"å­¦ç¿’ã‚µãƒ³ãƒ—ãƒ«æ•°: {training.get('samples', 0):,}",
                    "",
                    "ğŸ“Š **è©•ä¾¡æŒ‡æ¨™:**",
                    f"```",
                    f"å‹åˆ©AUC:       {win_auc:.4f} {get_icon(win_auc, 0.70, 0.80)}",
                    f"è¤‡å‹AUC:       {place_auc:.4f} {get_icon(place_auc, 0.65, 0.75)}",
                    f"Brier(å‹åˆ©):   {win_brier:.4f} {get_icon(win_brier, 0.07, 0.05, True)}",
                    f"Top-3ã‚«ãƒãƒ¼ç‡: {top3_coverage*100:.1f}% {get_icon(top3_coverage, 0.55, 0.65)}",
                    f"```",
                    "",
                    "âš ï¸ æ”¹å–„ãªã—ã®ãŸã‚ç¾è¡Œãƒ¢ãƒ‡ãƒ«ã‚’ç¶­æŒ"
                ]

            payload = {"content": "\n".join(lines)}
            requests.post(webhook_url, json=payload, timeout=10)

        except Exception as e:
            logger.error(f"é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")

    def run_weekly_job(self, force_deploy: bool = False, notify: bool = True, years: int = 3):
        """é€±æ¬¡ã‚¸ãƒ§ãƒ–ã‚’å®Ÿè¡Œ"""
        logger.info("=" * 50)
        logger.info(f"é€±æ¬¡ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’é–‹å§‹: {datetime.now()}")
        logger.info("=" * 50)

        result = {
            'date': date.today().isoformat(),
            'deployed': False
        }

        # 1. æ–°ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        training_result = self.train_new_model(years=years)
        result['training'] = training_result

        if training_result['status'] != 'success':
            logger.error(f"å­¦ç¿’å¤±æ•—: {training_result}")
            return result

        new_model_path = training_result['model_path']

        # 2. æ¯”è¼ƒï¼ˆç¾è¡Œãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆï¼‰
        if self.current_model_path.exists():
            comparison = self.compare_models(new_model_path)
            result['comparison'] = comparison

            if comparison['status'] == 'success':
                # æ”¹å–„ãŒã‚ã‚Œã°ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆã¾ãŸã¯å¼·åˆ¶ãƒ‡ãƒ—ãƒ­ã‚¤ï¼‰
                if comparison['improvement'] > 0 or force_deploy:
                    self.deploy_new_model(new_model_path)
                    result['deployed'] = True
                    logger.info("æ–°ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã—ãŸ")
                else:
                    logger.info("æ”¹å–„ãªã—ã€ç¾è¡Œãƒ¢ãƒ‡ãƒ«ã‚’ç¶­æŒ")
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    Path(new_model_path).unlink()
            elif force_deploy:
                # æ¯”è¼ƒå¤±æ•—ã§ã‚‚å¼·åˆ¶ãƒ‡ãƒ—ãƒ­ã‚¤
                self.deploy_new_model(new_model_path)
                result['deployed'] = True
                logger.info("å¼·åˆ¶ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã—ãŸï¼ˆæ¯”è¼ƒå¤±æ•—ï¼‰")
        else:
            # ç¾è¡Œãƒ¢ãƒ‡ãƒ«ãŒãªã„å ´åˆã¯ãã®ã¾ã¾ãƒ‡ãƒ—ãƒ­ã‚¤
            shutil.move(new_model_path, self.current_model_path)
            result['deployed'] = True
            result['comparison'] = {'note': 'initial_deployment'}
            logger.info("åˆå›ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†")

        # 3. é€šçŸ¥
        if notify:
            self.send_notification(result)

        # çµæœä¿å­˜
        result_path = self.model_dir / f"retrain_result_{date.today().strftime('%Y%m%d')}.json"
        with open(result_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        return result


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    import argparse

    parser = argparse.ArgumentParser(description="é€±æ¬¡ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’ï¼ˆensemble_modelï¼‰")
    parser.add_argument("--force", "-f", action="store_true", help="æ”¹å–„ãªã—ã§ã‚‚ãƒ‡ãƒ—ãƒ­ã‚¤")
    parser.add_argument("--no-notify", action="store_true", help="Discordé€šçŸ¥ã—ãªã„")
    parser.add_argument("--years", "-y", type=int, default=3, help="å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹å¹´æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3å¹´ï¼‰")

    args = parser.parse_args()

    retrain = WeeklyRetrain()
    result = retrain.run_weekly_job(
        force_deploy=args.force,
        notify=not args.no_notify,
        years=args.years
    )

    print("\n=== å†å­¦ç¿’çµæœ ===")
    print(json.dumps(result, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
